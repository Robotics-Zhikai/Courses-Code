## CMU csapp课程课后lab
## csapp笔记
### 第五章 程序优化
* 算法确定后，如何让其运行更快；编译器友好的代码，什么代码编译器可以优化
* 乘法操作是非常耗时的
* 减少过程调用、消除不必要的内存引用等编译器友好的代码
* 程序员可以控制程序中不同的计算部分使用了多少个时钟周期
* 顺序的指令序列，处理器可以读到多条顺序的指令序列，然后提取出独立的部分并行执行
* 循环展开、矢量化
### 第七章 链接
* 编译器驱动程序
	* main.c通过预处理器翻译成一个ASCII码的中间文件main.i，C编译器将main.i翻译成一个ASCII汇编语言文件main.s，然后驱动程序运行汇编器，将main.s翻译成一个可重定位目标文件main.o。最后连接器程序将各目标文件组合起来，创建一个可执行目标文件。最后加载器把该可执行文件加载到内存中，然后把控制转移到程序的开头。可用execve加载.out文件，详情可见csapp P585
	* 一个典型的ELF可重定位目标文件包含下面几个节（部分，不是全部）：
		* .text 已编译程序的机器代码
		* .rodata 只读数据
		* .data 已初始化的全局和静态变量
		* .bss 未初始化的全局和静态变量，以及所有被初始化为0的全局或静态变量。目标文件格式区分已初始化和未初始化变量是为了空间效率：在目标文件中未初始化变量不需要占据任何实际的磁盘空间。运行时，在内存中分配这些变量，初始值为0.
		* .line 原始C源程序中的行号和.text节中机器指令之间的映射。只有以-g选项调用编译器驱动程序时，才会得到这张表。
	* 静态库
		* 所有的编译系统提供一种机制，将所有相关的目标模块打包成一个单独的文件，成为静态库，它可以用作连接器的输入。
		* 相关的函数可以被编译成独立的目标模块，然后封装成一个单独的静态库文件。在Linux中，静态库以一种称为存档的特殊文件格式存放在磁盘中。存档文件是一组连接起来的可重定位目标文件的集合，有一个头部来描述每个成员目标文件的大小和位置。存档文件名由后缀.a标识。
		* 在链接时，链接器将只复制被程序引用的目标模块，这就减少了可执行文件在磁盘和内存中的大小。
	* 动态连接共享库
		* 静态库的缺点
			* 静态库需要定期维护和更新，要想使用某个库的最新版本，程序员必须以某种方式了解到该库的更新情况，然后显式地将他们的程序与更新了的库重新链接。
			* 对于使用比较频繁的标准I/O函数，在运行时这些函数的代码会被复制到每个运行进程的文本段中，这是对内存资源的极大浪费。
		* 共享库的共享方式
			* 在任何给定的文件系统中，对于一个库只有一个.so文件，所有引用该库的可执行目标文件共享这个.so文件中的代码和数据
			* 在内存中，一个共享库的.text节的一个副本可以被不同的正在运行的进程共享
### 第八章 异常控制流
* 段故障（segmentation fault）
	* 一个程序引用了未定义的虚拟内存区域
	* 程序试图写一个只读的文本段
* 进程上下文是由程序正确运行所需的状态所组成的。上下文就是内核重新启动一个被抢占的进程所需的状态。它由一些对象的值组成。
	* 这个状态包括存放在内存中的程序的代码和数据
	* 通用目的寄存器、浮点寄存器、程序计数器、用户栈、状态寄存器、内核栈和各种内核数据结构，比如描述地址空间的页表、包含有关当前进程信息的进程表，以及包含进程已打开文件的信息的文件表。
* 为了使操作系统内核提供一个无懈可击的进程抽象，处理器必须提供一种机制，限制一个应用可以执行的指令以及它可以访问的地址空间范围。
	* 设置了模式位时，进程就运行在内核模式中。一个运行在内核模式的进程可以执行指令集中的任何指令，并且可以访问系统中的任何内存位置。
	* 没有设置模式位时，系统就运行在用户模式中。用户模式中的进程不允许执行特权指令，比如停止处理器、改变模式位，或者发起一个I/O操作。也不允许用户模式中的进程直接引用地址空间中的内核区内的代码和数据。任何这样的尝试都会导致致命的保护故障。用户程序必须通过调用系统调用接口间接地访问内核代码和数据。
* 安全的信号处理方法
	* 处理程序要尽可能简单
	* 在处理程序中只调用异步信号安全的函数（能够被进程的信号处理函数安全的调用）
		* 可重入的（例如只访问局部变量）
			* 一个调用不可重入函数的例子：进程正在调用malloc，然后被一信号处理函数打断，该信号处理函数又调用了malloc，这时候就会出现问题——因为malloc通常为它所分配的存储区维护一个链表，而插入执行信号处理程序时，进程可能正在更改此链表
		* 它不能被信号处理程序中断
	* 保存和恢复errno
	* 阻塞所有信号，保护对共享全局数据结构的访问
	* 用volatile声明全局变量。该声明可以告知编译器不要缓存该声明所声明的变量，强迫编译器每次在代码中引用g时，都要从内存中读取g的值。
* 非本地跳转（将控制直接从一个函数转移到另一个当前正在执行的函数而不需要经过正常的调用-返回栈规则，非本地跳转是通过setjmp和longjmp函数来提供的）
	* 非本地跳转的一个重要应用就是允许从一个深层嵌套的函数调用中立即返回，通常是由检测到某个错误情况引起的。如果在一个深层嵌套的函数调用中发现了一个错误情况，我们可以使用非本地跳转直接返回到一个普通的本地化的错误处理程序，而不是费力的解开调用栈。
	* 非本地跳转的另一个重要应用是使一个信号处理程序分支到一个特殊的代码位置，而不是返回到被信号到达中断了的指令位置
	* C++和Java提供的异常机制是较高层次的，可以把try语句中的catch子句看做类似于setjmp函数，throw看成longjmp函数
### 第九章虚拟内存
* 虚拟内存提供了三个重要的能力
	* 把主存看成是一个存储在磁盘上的地址空间的高速缓存，在主存中只保存活动区域
	* 为每个进程提供了一致的地址空间，从而简化了内存管理
	* 保护了每个进程的地址空间不被其他进程破坏
* CPU芯片上叫做**内存管理单元**（Memory Management Unit，MMU）的专用硬件，利用存放在主存中的查询表来动态翻译虚拟地址，该表的内容由操作系统管理。
* 虚拟内存作为缓存的工具
	* 虚拟内存系统在主存中缓存虚拟页
	* 每次地址翻译硬件将一个虚拟地址转换为物理地址时，都会读取页表
* 虚拟内存作为内存管理的工具
	* 操作系统为每个进程提供了一个独立的页表，因而也就是一个独立的虚拟地址空间
	* 简化链接。独立的地址空间允许每个进程的内存映像使用相同的基本格式，而不管代码和数据实际存放在物理内存的何处。一个给定的linux系统上的每个进程都使用类似的内存格式。这样的一致性极大地简化了链接器的设计和实现。
	* 简化加载。加载器从不从磁盘到内存实际复制任何数据，主要操作的是页表进行的映射，进而在运行时动态调入数据页。
	* 简化共享。一般而言，每个进程都有自己的私有代码、数据、堆以及栈区域，是不和其他进程共享的。然而，在某些情况中，还是需要进程来共享代码和数据，比如每个进程必须调用相同的操作系统内核代码等。
	* 简化内存分配。操作系统分配一个适当数字个连续的虚拟内存页面。
* 虚拟内存作为内存保护的工具
	* 每次CPU生成一个地址时，地址翻译硬件都会读一个PTE（页表条目，page table entry），所以通过在PTE上添加一些额外的许可位来控制对一个虚拟页面内容的访问十分简单。比如某一页可被标记为是否运行在内核（超级用户）模式下才能被访问，或者控制某页的读写访问权限。如果一条指令违反了这些许可条件，那么CPU就触发一个一般保护故障，将控制传递给一个内核中的异常处理程序，Linux shell将这种异常报告为“段错误”（segmentation fault）。
* 地址翻译（虚拟地址翻译发生在高速缓存查找之前）
	* CPU中的一个控制寄存器——页表基址寄存器指向当前页表。
	* n位的虚拟地址包含两个部分：p位的虚拟页面偏移（VPO），n-p位的虚拟页号（VPN）。MMU利用VPN来选择适当的PTE，提取出页表条目中物理页号（PPN）与VPO串联起来就是相应的物理地址。物理页面偏移（PPO）和VPO是相同的。
	* 页表条目（PTE）可以缓存在L1cache中，就像其他的数据字一样。
	* MMU中包括了一个关于PTE的小的缓存，称为**翻译后备缓冲器（Translation Lookaside Buffer，TLB）**，是一个小的、虚拟寻址的缓存。输入是虚拟地址，输出是PTE
	* 优化地址翻译（主要是把PPN和PPO并行化了）
		* 将VPO传送到L1 cache中，进行组匹配，并读出相应的标记
		* 并行地，将VPN传送到TLB中请求一个页表条目进而翻译为PPN
		* 将上述二者拼起来就是最终的物理地址
* 内存映射
	* 将一个虚拟区域与一个磁盘上的对象关联起来，以初始化这个虚拟内存区域的内容。一个区域可以映射到一个普通磁盘文件的连续部分，例如一个可执行目标文件。